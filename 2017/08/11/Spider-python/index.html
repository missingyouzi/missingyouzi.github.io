<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Second Day | My_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="python3爬虫123456789101112#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &amp;quot;&amp;quot;res = requests.get(url)soup = BeautifulSoup(r">
<meta property="og:type" content="article">
<meta property="og:title" content="Second Day">
<meta property="og:url" content="missingyouzi.github.io/2017/08/11/Spider-python/index.html">
<meta property="og:site_name" content="My_Blog">
<meta property="og:description" content="python3爬虫123456789101112#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &amp;quot;&amp;quot;res = requests.get(url)soup = BeautifulSoup(r">
<meta property="og:updated_time" content="2017-09-18T08:57:19.714Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Second Day">
<meta name="twitter:description" content="python3爬虫123456789101112#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &amp;quot;&amp;quot;res = requests.get(url)soup = BeautifulSoup(r">
  
    <link rel="alternate" href="/atom.xml" title="My_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <!--<link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">-->
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">My_Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">ZQ&#39;s_Blog</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="missingyouzi.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Spider-python" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/11/Spider-python/" class="article-date">
  <time datetime="2017-08-11T07:08:15.000Z" itemprop="datePublished">2017-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Second Day
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="python3爬虫"><a href="#python3爬虫" class="headerlink" title="python3爬虫"></a>python3爬虫</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#! /usr/env/bin python  #windows下不需要这一行</div><div class="line">#coding:utf-8   #python3不需要这一行</div><div class="line"></div><div class="line">import requests</div><div class="line">from bs4 import BeautifulSoup</div><div class="line"></div><div class="line">url = &quot;&quot;</div><div class="line">res = requests.get(url)</div><div class="line">soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</div><div class="line">a = soup.select(&apos;a&apos;)</div><div class="line">#对class下的标签使用. 对id下的标签使用# 可以在标签后加标签</div><div class="line">soup.select(&apos;a p&apos;) #查找a标签下的p标签内容</div></pre></td></tr></table></figure>
<h1 id="以下是写python爬虫可能需要的东西（反正是python基础）"><a href="#以下是写python爬虫可能需要的东西（反正是python基础）" class="headerlink" title="以下是写python爬虫可能需要的东西（反正是python基础）"></a>以下是写python爬虫可能需要的东西（反正是python基础）</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">strip()清除空白字符</div><div class="line">resp.text返回的是Unicode型的数据。</div><div class="line">resp.content返回的是bytes型也就是二进制的数据。</div><div class="line">也就是说，如果你想取文本，可以通过r.text。</div><div class="line">如果想取图片，文件，则可以通过r.content。</div><div class="line">（resp.json()返回的是json格式数据）</div></pre></td></tr></table></figure>
<h1 id="以下是本人写的爬取豆瓣电影top250的代码："><a href="#以下是本人写的爬取豆瓣电影top250的代码：" class="headerlink" title="以下是本人写的爬取豆瓣电影top250的代码："></a>以下是本人写的爬取豆瓣电影top250的代码：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div></pre></td><td class="code"><pre><div class="line">#并没有面向对象编程，因为没有对象（摊手）</div><div class="line">&quot;&quot;&quot;</div><div class="line">@version: 1.0</div><div class="line">@author: Z-Q</div><div class="line">@software: PyCharm</div><div class="line">@file: finally.py</div><div class="line">@time: 2017/7/28 9:49</div><div class="line">&quot;&quot;&quot;</div><div class="line">#获取首页的url，之后从第一页获取别的页码的url，之后一起解析</div><div class="line">import requests #用于发送网络请求</div><div class="line">from bs4 import BeautifulSoup   #用于解析html代码</div><div class="line">import threading    #使用多线程</div><div class="line">import os   #使用sleep()函数用于延迟爬取（虽然豆瓣好像对于小规模爬虫管的不太严？）</div><div class="line"></div><div class="line">#解析url，并返回soup对象</div><div class="line">def jiexi(url):</div><div class="line">	res = requests.get(url)</div><div class="line">	soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</div><div class="line">	return soup</div><div class="line"></div><div class="line">#将所有的url汇聚到一个list中</div><div class="line">def all_htmls(html):</div><div class="line">	soup_all_list = []     #创建空列表，用于存放url地址</div><div class="line">	soup_all_list.append(html)  #添加首地址</div><div class="line">	soup1 = jiexi(html)</div><div class="line">	soup_find_class = soup1.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;paginator&apos;&#125;)</div><div class="line">	for href in soup_find_class.find_all(&apos;a&apos;):  #发现所有a标签,用于寻找剩下的url网址</div><div class="line">		href_we_need = href.get(&apos;href&apos;)</div><div class="line">		href_next = html.split(&apos;?&apos;)[0] + href_we_need</div><div class="line">		soup_all_list.append(href_next)</div><div class="line">	return soup_all_list       #返回url列表</div><div class="line"></div><div class="line">#获取排行榜，并写入一个txt文件中</div><div class="line">def get_Rank(url_list):</div><div class="line">	count = 1</div><div class="line">	all_text = &apos;&apos;</div><div class="line">	for url_from_list in url_list:</div><div class="line">		soup_jieguo = jiexi(url_from_list)</div><div class="line">		class1 = soup_jieguo.find(&apos;ol&apos;,attrs=&#123;&apos;class&apos;: &apos;grid_view&apos;&#125;)</div><div class="line">		for li in class1.find_all(&apos;li&apos;):</div><div class="line">			title = li.find_all(&apos;span&apos;, attrs=&#123;&apos;class&apos;: &apos;title&apos;&#125;)[0].text</div><div class="line">			other = li.find_all(&apos;span&apos;, attrs=&#123;&apos;class&apos;: &apos;other&apos;&#125;)[0].text</div><div class="line">			#playable = li.find(&apos;span&apos;,attrs=&#123;&apos;class&apos;: &apos;playable&apos;&#125;).text</div><div class="line">			try:</div><div class="line">				playable = li.find(&apos;span&apos;,attrs=&#123;&apos;class&apos;: &apos;playable&apos;&#125;).text</div><div class="line">			except:</div><div class="line">				playable = &apos;[不可播放]&apos;</div><div class="line">			text = &apos;TOP %s :&apos; % count + title + other + playable</div><div class="line">			count += 1</div><div class="line">			#list_we_need.append(text)</div><div class="line">			all_text = all_text + text + &apos;\n&apos;</div><div class="line">	with open(&apos;豆瓣电影排行榜.txt&apos;, &apos;w&apos;, encoding=&apos;utf-8&apos;) as f:</div><div class="line">		f.write(all_text)</div><div class="line">	print(&apos;Rank list has been Done!&apos;)</div><div class="line">	return 0</div><div class="line"></div><div class="line">#在当前目录下建立一个新目录，用于存放图片</div><div class="line">def make_new_dir():</div><div class="line">	now_path = os.getcwd()</div><div class="line">	os.mkdir(now_path + &apos;\pictures&apos;)</div><div class="line">	img_path = now_path + &apos;\pictures&apos;</div><div class="line">	return img_path</div><div class="line">#获取所有图片,并写入pictures文件夹中</div><div class="line">def get_pic(url_list):</div><div class="line">	try:    #创建新文件夹</div><div class="line">		new_dir = make_new_dir()</div><div class="line">	except: #如果存在名为pictures的文件夹，则不用新建了</div><div class="line">		new_dir = os.getcwd() + &apos;\pictures&apos;</div><div class="line">	count = 0   #排名</div><div class="line">	for url in url_list:    #遍历url_list</div><div class="line">		soup2 = jiexi(url)</div><div class="line">		for img in soup2.find_all(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;pic&apos;&#125;):</div><div class="line">			count += 1</div><div class="line">			alt = img.find(&apos;img&apos;).get(&apos;alt&apos;)</div><div class="line">			src_webp = img.find(&apos;img&apos;).get(&apos;src&apos;)</div><div class="line">			img = requests.get(src_webp)</div><div class="line">			rank = &apos;TOP&#123;&#125;： &apos;.format(count)   #不能出现英文冒号(真TM坑爹)</div><div class="line">			path = new_dir + &apos;\\&apos; + rank + alt + &apos;.jpg&apos;</div><div class="line">			#print(path)</div><div class="line">			with open(path, &apos;wb&apos;) as f:</div><div class="line">				f.write(img.content)</div><div class="line">	print(&apos;Pictures had been Downloaded!&apos;)</div><div class="line"></div><div class="line">def main(url):</div><div class="line">	html_list = all_htmls(url)</div><div class="line">	get_Rank(html_list)</div><div class="line">	get_pic(html_list)</div><div class="line">	#threading_lock.release()</div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">	#threading_lock = threading.BoundedSemaphore(value=10)</div><div class="line">	url = &apos;https://movie.douban.com/top250?start=0&amp;filter=&apos;</div><div class="line">	main(url)</div><div class="line">	#threading_lock.acquire()</div><div class="line">	#t = threading.Thread(target=main, args=url)</div><div class="line">	#t.start()</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="missingyouzi.github.io/2017/08/11/Spider-python/" data-id="cj7pxu9mr00015wd03v9xnoxa" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2017/08/11/C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">C</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/08/11/Spider-python/">Second Day</a>
          </li>
        
          <li>
            <a href="/2017/08/11/C/">C</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 ZQ<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>