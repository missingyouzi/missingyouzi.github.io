<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Second Day | My_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Python3爬虫爬取豆瓣电影Top25012345678910#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &quot;&quot;res = requests.get(url)soup = BeautifulSoup(res">
<meta property="og:type" content="article">
<meta property="og:title" content="Second Day">
<meta property="og:url" content="missingyouzi.github.io/2017/08/11/Spider-python/index.html">
<meta property="og:site_name" content="My_Blog">
<meta property="og:description" content="Python3爬虫爬取豆瓣电影Top25012345678910#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &quot;&quot;res = requests.get(url)soup = BeautifulSoup(res">
<meta property="og:updated_time" content="2017-09-18T10:46:44.043Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Second Day">
<meta name="twitter:description" content="Python3爬虫爬取豆瓣电影Top25012345678910#! /usr/env/bin python  #windows下不需要这一行#coding:utf-8   #python3不需要这一行import requestsfrom bs4 import BeautifulSoupurl = &quot;&quot;res = requests.get(url)soup = BeautifulSoup(res">
  
    <link rel="alternate" href="/atom.xml" title="My_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <!--<link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">-->
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">My_Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">ZQ&#39;s_Blog</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="missingyouzi.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Spider-python" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/11/Spider-python/" class="article-date">
  <time datetime="2017-08-11T07:08:15.000Z" itemprop="datePublished">2017-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Second Day
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Python3爬虫爬取豆瓣电影Top250"><a href="#Python3爬虫爬取豆瓣电影Top250" class="headerlink" title="Python3爬虫爬取豆瓣电影Top250"></a>Python3爬虫爬取豆瓣电影Top250</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/env/bin python  #windows下不需要这一行</span></div><div class="line"><span class="comment">#coding:utf-8   #python3不需要这一行</span></div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line">url = <span class="string">""</span></div><div class="line">res = requests.get(url)</div><div class="line">soup = BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</div><div class="line">a = soup.select(<span class="string">'a'</span>)</div><div class="line"><span class="comment">#对class下的标签使用. 对id下的标签使用# 可以在标签后加标签</span></div><div class="line">soup.select(<span class="string">'a p'</span>) <span class="comment">#查找a标签下的p标签内容</span></div></pre></td></tr></table></figure>
<h1 id="以下是写python爬虫可能需要的东西（反正是python基础）"><a href="#以下是写python爬虫可能需要的东西（反正是python基础）" class="headerlink" title="以下是写python爬虫可能需要的东西（反正是python基础）"></a>以下是写python爬虫可能需要的东西（反正是python基础）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">strip()清除空白字符</div><div class="line">resp.text返回的是Unicode型的数据。</div><div class="line">resp.content返回的是bytes型也就是二进制的数据。</div><div class="line">也就是说，如果你想取文本，可以通过r.text。</div><div class="line">如果想取图片，文件，则可以通过r.content。</div><div class="line">（resp.json()返回的是json格式数据）</div></pre></td></tr></table></figure>
<h1 id="以下是本人写的爬取豆瓣电影top250的代码："><a href="#以下是本人写的爬取豆瓣电影top250的代码：" class="headerlink" title="以下是本人写的爬取豆瓣电影top250的代码："></a>以下是本人写的爬取豆瓣电影top250的代码：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#并没有面向对象编程，因为没有对象（摊手）</span></div><div class="line"><span class="string">"""</span></div><div class="line">@version: 1.0</div><div class="line">@author: Z-Q</div><div class="line">@software: PyCharm</div><div class="line">@file: finally.py</div><div class="line">@time: 2017/7/28 9:49</div><div class="line">"""</div><div class="line"><span class="comment">#获取首页的url，之后从第一页获取别的页码的url，之后一起解析</span></div><div class="line"><span class="keyword">import</span> requests <span class="comment">#用于发送网络请求</span></div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup   <span class="comment">#用于解析html代码</span></div><div class="line"><span class="keyword">import</span> threading    <span class="comment">#使用多线程</span></div><div class="line"><span class="keyword">import</span> os   <span class="comment">#使用sleep()函数用于延迟爬取（虽然豆瓣好像对于小规模爬虫管的不太严？）</span></div><div class="line"></div><div class="line"><span class="comment">#解析url，并返回soup对象</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">jiexi</span><span class="params">(url)</span>:</span></div><div class="line">	res = requests.get(url)</div><div class="line">	soup = BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</div><div class="line">	<span class="keyword">return</span> soup</div><div class="line"></div><div class="line"><span class="comment">#将所有的url汇聚到一个list中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">all_htmls</span><span class="params">(html)</span>:</span></div><div class="line">	soup_all_list = []     <span class="comment">#创建空列表，用于存放url地址</span></div><div class="line">	soup_all_list.append(html)  <span class="comment">#添加首地址</span></div><div class="line">	soup1 = jiexi(html)</div><div class="line">	soup_find_class = soup1.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'paginator'</span>&#125;)</div><div class="line">	<span class="keyword">for</span> href <span class="keyword">in</span> soup_find_class.find_all(<span class="string">'a'</span>):  <span class="comment">#发现所有a标签,用于寻找剩下的url网址</span></div><div class="line">		href_we_need = href.get(<span class="string">'href'</span>)</div><div class="line">		href_next = html.split(<span class="string">'?'</span>)[<span class="number">0</span>] + href_we_need</div><div class="line">		soup_all_list.append(href_next)</div><div class="line">	<span class="keyword">return</span> soup_all_list       <span class="comment">#返回url列表</span></div><div class="line"></div><div class="line"><span class="comment">#获取排行榜，并写入一个txt文件中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_Rank</span><span class="params">(url_list)</span>:</span></div><div class="line">	count = <span class="number">1</span></div><div class="line">	all_text = <span class="string">''</span></div><div class="line">	<span class="keyword">for</span> url_from_list <span class="keyword">in</span> url_list:</div><div class="line">		soup_jieguo = jiexi(url_from_list)</div><div class="line">		class1 = soup_jieguo.find(<span class="string">'ol'</span>,attrs=&#123;<span class="string">'class'</span>: <span class="string">'grid_view'</span>&#125;)</div><div class="line">		<span class="keyword">for</span> li <span class="keyword">in</span> class1.find_all(<span class="string">'li'</span>):</div><div class="line">			title = li.find_all(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'title'</span>&#125;)[<span class="number">0</span>].text</div><div class="line">			other = li.find_all(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'other'</span>&#125;)[<span class="number">0</span>].text</div><div class="line">			<span class="comment">#playable = li.find('span',attrs=&#123;'class': 'playable'&#125;).text</span></div><div class="line">			<span class="keyword">try</span>:</div><div class="line">				playable = li.find(<span class="string">'span'</span>,attrs=&#123;<span class="string">'class'</span>: <span class="string">'playable'</span>&#125;).text</div><div class="line">			<span class="keyword">except</span>:</div><div class="line">				playable = <span class="string">'[不可播放]'</span></div><div class="line">			text = <span class="string">'TOP %s :'</span> % count + title + other + playable</div><div class="line">			count += <span class="number">1</span></div><div class="line">			<span class="comment">#list_we_need.append(text)</span></div><div class="line">			all_text = all_text + text + <span class="string">'\n'</span></div><div class="line">	<span class="keyword">with</span> open(<span class="string">'豆瓣电影排行榜.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</div><div class="line">		f.write(all_text)</div><div class="line">	print(<span class="string">'Rank list has been Done!'</span>)</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment">#在当前目录下建立一个新目录，用于存放图片</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_new_dir</span><span class="params">()</span>:</span></div><div class="line">	now_path = os.getcwd()</div><div class="line">	os.mkdir(now_path + <span class="string">'\pictures'</span>)</div><div class="line">	img_path = now_path + <span class="string">'\pictures'</span></div><div class="line">	<span class="keyword">return</span> img_path</div><div class="line"><span class="comment">#获取所有图片,并写入pictures文件夹中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pic</span><span class="params">(url_list)</span>:</span></div><div class="line">	<span class="keyword">try</span>:    <span class="comment">#创建新文件夹</span></div><div class="line">		new_dir = make_new_dir()</div><div class="line">	<span class="keyword">except</span>: <span class="comment">#如果存在名为pictures的文件夹，则不用新建了</span></div><div class="line">		new_dir = os.getcwd() + <span class="string">'\pictures'</span></div><div class="line">	count = <span class="number">0</span>   <span class="comment">#排名</span></div><div class="line">	<span class="keyword">for</span> url <span class="keyword">in</span> url_list:    <span class="comment">#遍历url_list</span></div><div class="line">		soup2 = jiexi(url)</div><div class="line">		<span class="keyword">for</span> img <span class="keyword">in</span> soup2.find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'pic'</span>&#125;):</div><div class="line">			count += <span class="number">1</span></div><div class="line">			alt = img.find(<span class="string">'img'</span>).get(<span class="string">'alt'</span>)</div><div class="line">			src_webp = img.find(<span class="string">'img'</span>).get(<span class="string">'src'</span>)</div><div class="line">			img = requests.get(src_webp)</div><div class="line">			rank = <span class="string">'TOP&#123;&#125;： '</span>.format(count)   <span class="comment">#不能出现英文冒号(真TM坑爹)</span></div><div class="line">			path = new_dir + <span class="string">'\\'</span> + rank + alt + <span class="string">'.jpg'</span></div><div class="line">			<span class="comment">#print(path)</span></div><div class="line">			<span class="keyword">with</span> open(path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">				f.write(img.content)</div><div class="line">	print(<span class="string">'Pictures had been Downloaded!'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(url)</span>:</span></div><div class="line">	html_list = all_htmls(url)</div><div class="line">	get_Rank(html_list)</div><div class="line">	get_pic(html_list)</div><div class="line">	<span class="comment">#threading_lock.release()</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	<span class="comment">#threading_lock = threading.BoundedSemaphore(value=10)</span></div><div class="line">	url = <span class="string">'https://movie.douban.com/top250?start=0&amp;filter='</span></div><div class="line">	main(url)</div><div class="line">	<span class="comment">#threading_lock.acquire()</span></div><div class="line">	<span class="comment">#t = threading.Thread(target=main, args=url)</span></div><div class="line">	<span class="comment">#t.start()</span></div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="missingyouzi.github.io/2017/08/11/Spider-python/" data-id="cj7q1s11500035kd0nym59eul" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/09/18/Python-based/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Python_based
        
      </div>
    </a>
  
  
    <a href="/2017/08/11/C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">C</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/09/18/JavaBased/">JavaBased</a>
          </li>
        
          <li>
            <a href="/2017/09/18/Python-based/">Python_based</a>
          </li>
        
          <li>
            <a href="/2017/08/11/Spider-python/">Second Day</a>
          </li>
        
          <li>
            <a href="/2017/08/11/C/">C</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 ZQ<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>